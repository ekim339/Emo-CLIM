{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths:\n",
    "ORIG_SPLIT_METADATA_FILES = {\n",
    "    \"unbalanced_train\": \"/proj/systewar/datasets/audioset_music_mood/metadata_unbalanced_train.csv\",\n",
    "    \"eval\": \"/proj/systewar/datasets/audioset_music_mood/metadata_eval.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script options:\n",
    "N_class_test = 100     # number of samples per class in (new) test set\n",
    "new_split_metadata_dir = \"/proj/systewar/datasets/audioset_music_mood/new_split_metadata_files\"\n",
    "new_split_metadata_files = {\n",
    "    \"train\": \"/proj/systewar/datasets/audioset_music_mood/new_split_metadata_files/metadata_train.csv\",\n",
    "    \"test\": \"/proj/systewar/datasets/audioset_music_mood/new_split_metadata_files/metadata_test.csv\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading unbalanced_train set labels...\n",
      "Loading eval set labels...\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13395 entries, 0 to 13394\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   orig_subset     13395 non-null  object\n",
      " 1   file_name       13395 non-null  object\n",
      " 2   length_samples  13395 non-null  int64 \n",
      " 3   label           13395 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 418.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load original split metadata files:\n",
    "orig_split_metadata_dfs = {}\n",
    "for subset, file_path in ORIG_SPLIT_METADATA_FILES.items():\n",
    "    print(\"Loading {} set labels...\".format(subset))\n",
    "    orig_split_metadata_dfs[subset] = pd.read_csv(file_path)\n",
    "\n",
    "# concatenate original split labels into a single dataframe:\n",
    "all_metadata = pd.concat(orig_split_metadata_dfs.values(), axis=\"index\")\n",
    "all_metadata = all_metadata.reset_index(drop=True)\n",
    "print()\n",
    "print(all_metadata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 700 entries, 10980 to 3237\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   orig_subset     700 non-null    object\n",
      " 1   file_name       700 non-null    object\n",
      " 2   length_samples  700 non-null    int64 \n",
      " 3   label           700 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 27.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# group by emotion class label:\n",
    "all_metadata_groups = all_metadata.groupby(by=\"label\", axis=\"index\")\n",
    "\n",
    "# construct stratified test set by randomly sampling from each class:\n",
    "metadata_test = all_metadata_groups.sample(n=N_class_test, random_state=42)\n",
    "print(metadata_test.info())\n",
    "\n",
    "# sanity check:\n",
    "for count in metadata_test[\"label\"].value_counts():\n",
    "    assert count == N_class_test, \"Error with creating stratified test set.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12695 entries, 0 to 13394\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   orig_subset     12695 non-null  object\n",
      " 1   file_name       12695 non-null  object\n",
      " 2   length_samples  12695 non-null  int64 \n",
      " 3   label           12695 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 495.9+ KB\n",
      "None\n",
      "\n",
      "Exciting music    4431\n",
      "Tender music      3214\n",
      "Scary music       1253\n",
      "Sad music         1242\n",
      "Happy music       1006\n",
      "Angry music        794\n",
      "Funny music        755\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# construct training set:\n",
    "metadata_train = all_metadata.drop(index=list(metadata_test.index))\n",
    "print(metadata_train.info())\n",
    "print()\n",
    "print(metadata_train[\"label\"].value_counts())\n",
    "\n",
    "# sanity check:\n",
    "assert set(metadata_train.index).isdisjoint(set(metadata_test.index)), \"Train and test sets are not disjoint.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indices:\n",
    "metadata_train = metadata_train.reset_index(drop=True)\n",
    "metadata_test = metadata_test.reset_index(drop=True)\n",
    "\n",
    "# more sanity checks:\n",
    "assert all_metadata.shape[0] == metadata_train.shape[0] + metadata_test.shape[0], \"Train and test set sizes don't add up.\"\n",
    "assert set(metadata_train[\"file_name\"].tolist()).isdisjoint(set(metadata_test[\"file_name\"].tolist())), \"Train and test sets are not disjoint.\"\n",
    "class_counts_all = all_metadata[\"label\"].value_counts()\n",
    "class_counts_train = metadata_train[\"label\"].value_counts()\n",
    "class_counts_test = metadata_test[\"label\"].value_counts()\n",
    "for class_label in all_metadata_groups.groups.keys():\n",
    "    assert class_counts_all[class_label] == class_counts_train[class_label] + class_counts_test[class_label], \"Error with splitting dataset.\"\n",
    "\n",
    "# save to files:\n",
    "os.makedirs(new_split_metadata_dir, exist_ok=True)\n",
    "metadata_train.to_csv(new_split_metadata_files[\"train\"], index=False)\n",
    "metadata_test.to_csv(new_split_metadata_files[\"test\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-queries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
