{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset root directory:\n",
    "DATA_DIR = \"/Users/eugenekim/Emo-CLIM/dataset/DeepEmotion\"\n",
    "# label subdirectories:\n",
    "SUBDIR_NAMES = [\"excitement\", \"anger\", \"fear\", \"amusement\", \"awe\", \"contentment\", \"disgust\", \"sadness\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# script options:\n",
    "val_fract = 0.1\n",
    "test_fract = 0.1\n",
    "metadata_files_split = {\n",
    "    \"train\": \"/Users/eugenekim/Emo-CLIM/dataset/DeepEmotion/metadata_train.csv\",\n",
    "    \"val\": \"/Users/eugenekim/Emo-CLIM/dataset/DeepEmotion/metadata_val.csv\",\n",
    "    \"test\": \"/Users/eugenekim/Emo-CLIM/dataset/DeepEmotion/metadata_test.csv\"\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Image Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset label directories:\n",
    "subdir_names = [name for name in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, name))]\n",
    "subdir_names = [name for name in subdir_names if name in SUBDIR_NAMES]\n",
    "assert set(subdir_names) == set(SUBDIR_NAMES), f\"Error: Found {subdir_names}, expected {SUBDIR_NAMES}\"\n",
    "# Use SUBDIR_NAMES for consistent ordering\n",
    "subdir_names = SUBDIR_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of dataset: 21829\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21829 entries, 0 to 21828\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  21829 non-null  object\n",
      " 1   file_name    21829 non-null  object\n",
      " 2   label        21829 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 511.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# get all image file paths:\n",
    "subdirs = []\n",
    "image_file_names = []\n",
    "emotion_labels = []\n",
    "for label in subdir_names:\n",
    "    # get file_names:\n",
    "    subdir_path = os.path.join(DATA_DIR, label)\n",
    "    file_names = [name for name in os.listdir(subdir_path) if os.path.isfile(os.path.join(subdir_path, name))]\n",
    "    n_images = len(file_names)\n",
    "    # save metadata:\n",
    "    subdirs += n_images * [label]\n",
    "    image_file_names += file_names\n",
    "    emotion_labels += n_images * [label]\n",
    "\n",
    "# create dataframe:\n",
    "all_metadata = pd.DataFrame(\n",
    "    data={\n",
    "        \"subdir_name\": subdirs,\n",
    "        \"file_name\": image_file_names,\n",
    "        \"label\": emotion_labels\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Total size of dataset: {}\".format(all_metadata.shape[0]))\n",
    "print()\n",
    "print(all_metadata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 80.00% of dataset = 17463 samples.\n",
      "Validation set size: 10.00% of dataset = 2183 samples.\n",
      "Test set size: 10.00% of dataset = 2183 samples.\n"
     ]
    }
   ],
   "source": [
    "# print subset sizes:\n",
    "train_set_size = int(np.around((1 - test_fract - val_fract) * all_metadata.shape[0]))\n",
    "print(\"Training set size: {:.2f}% of dataset = {} samples.\".format(100 * (1 - test_fract - val_fract), train_set_size))\n",
    "val_set_size = int(np.around(val_fract * all_metadata.shape[0]))\n",
    "print(\"Validation set size: {:.2f}% of dataset = {} samples.\".format(100 * val_fract, val_set_size))\n",
    "test_set_size = int(np.around(test_fract * all_metadata.shape[0]))\n",
    "print(\"Test set size: {:.2f}% of dataset = {} samples.\".format(100 * test_fract, test_set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of contentment images: 5130\n",
      "Number of amusement images: 4724\n",
      "Number of awe images: 2881\n",
      "Number of excitement images: 2725\n",
      "Number of sadness images: 2633\n",
      "Number of disgust images: 1591\n",
      "Number of anger images: 1176\n",
      "Number of fear images: 969\n"
     ]
    }
   ],
   "source": [
    "# print class distribution:\n",
    "label_counts = all_metadata[\"label\"].value_counts()\n",
    "for label in all_metadata[\"label\"].value_counts().index:\n",
    "    print(\"Number of {} images: {}\".format(label, label_counts[label]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2183 entries, 19379 to 2890\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  2183 non-null   object\n",
      " 1   file_name    2183 non-null   object\n",
      " 2   label        2183 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 68.2+ KB\n",
      "None\n",
      "\n",
      "Number of contentment images: 513\n",
      "Number of amusement images: 472\n",
      "Number of awe images: 288\n",
      "Number of excitement images: 273\n",
      "Number of sadness images: 263\n",
      "Number of disgust images: 159\n",
      "Number of anger images: 118\n",
      "Number of fear images: 97\n"
     ]
    }
   ],
   "source": [
    "# split into stratified training/val and test sets:\n",
    "metadata_train_val, metadata_test = train_test_split(all_metadata, test_size=test_set_size, stratify=all_metadata[\"label\"], random_state=42)\n",
    "assert metadata_test.shape[0] == test_set_size, \"Test set metadata has incorrect size.\"\n",
    "print(metadata_test.info())\n",
    "\n",
    "# print test set class distribution:\n",
    "print()\n",
    "label_counts = metadata_test[\"label\"].value_counts()\n",
    "for label in metadata_test[\"label\"].value_counts().index:\n",
    "    print(\"Number of {} images: {}\".format(label, label_counts[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2183 entries, 19808 to 7695\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   subdir_name  2183 non-null   object\n",
      " 1   file_name    2183 non-null   object\n",
      " 2   label        2183 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 68.2+ KB\n",
      "None\n",
      "\n",
      "Number of contentment images: 513\n",
      "Number of amusement images: 473\n",
      "Number of awe images: 288\n",
      "Number of excitement images: 272\n",
      "Number of sadness images: 263\n",
      "Number of disgust images: 159\n",
      "Number of anger images: 118\n",
      "Number of fear images: 97\n"
     ]
    }
   ],
   "source": [
    "# split into stratified training and validation sets:\n",
    "metadata_train, metadata_val = train_test_split(metadata_train_val, test_size=val_set_size, stratify=metadata_train_val[\"label\"], random_state=42)\n",
    "assert metadata_val.shape[0] == val_set_size, \"Validation set metadata has incorrect size.\"\n",
    "print(metadata_val.info())\n",
    "\n",
    "# print validation set class distribution:\n",
    "print()\n",
    "label_counts = metadata_val[\"label\"].value_counts()\n",
    "for label in metadata_val[\"label\"].value_counts().index:\n",
    "    print(\"Number of {} images: {}\".format(label, label_counts[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all subsets are disjoint:\n",
    "metadata_subsets = [metadata_train, metadata_val, metadata_test]\n",
    "subset_names = list(metadata_files_split.keys())\n",
    "for subset_1, name_1 in zip(metadata_subsets, subset_names):\n",
    "    for subset_2, name_2 in zip(metadata_subsets, subset_names):\n",
    "        if name_1 != name_2:\n",
    "            assert set(subset_1.index).isdisjoint(set(subset_2.index)), \"{} and {} are not disjoint\".format(name_1, name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset indices:\n",
    "metadata_train = metadata_train.reset_index(drop=True)\n",
    "metadata_val = metadata_val.reset_index(drop=True)\n",
    "metadata_test = metadata_test.reset_index(drop=True)\n",
    "\n",
    "# sanity checks:\n",
    "assert all_metadata.shape[0] == metadata_train.shape[0] + metadata_val.shape[0] + metadata_test.shape[0], \"Subset set sizes don't add up.\"\n",
    "# check that all subsets are disjoint:\n",
    "metadata_subsets = [metadata_train, metadata_val, metadata_test]\n",
    "subset_names = list(metadata_files_split.keys())\n",
    "for subset_1, name_1 in zip(metadata_subsets, subset_names):\n",
    "    for subset_2, name_2 in zip(metadata_subsets, subset_names):\n",
    "        if name_1 != name_2:\n",
    "            assert set(subset_1[\"file_name\"].tolist()).isdisjoint(set(subset_2[\"file_name\"].tolist())), \"{} and {} are not disjoint\".format(name_1, name_2)\n",
    "# more sanity checks:\n",
    "class_counts_all = all_metadata[\"label\"].value_counts()\n",
    "class_counts_train = metadata_train[\"label\"].value_counts()\n",
    "class_counts_val = metadata_val[\"label\"].value_counts()\n",
    "class_counts_test = metadata_test[\"label\"].value_counts()\n",
    "for class_label in all_metadata[\"label\"].unique().tolist():\n",
    "    assert class_counts_all[class_label] == class_counts_train[class_label] + class_counts_val[class_label] + class_counts_test[class_label], \"Error with splitting dataset.\"\n",
    "\n",
    "# save to file:\n",
    "metadata_train.to_csv(metadata_files_split[\"train\"], index=False)\n",
    "metadata_val.to_csv(metadata_files_split[\"val\"], index=False)\n",
    "metadata_test.to_csv(metadata_files_split[\"test\"], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal-queries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
